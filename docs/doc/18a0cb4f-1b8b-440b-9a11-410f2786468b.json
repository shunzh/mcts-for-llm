{
    "summary": "The code initializes a UCT agent for HuggingFace transformer models and defines a \"generate\" function, adapting reward functions as needed. It resets the environment, plots action trees, and returns results after clearing the agent for next generation call.",
    "details": [
        {
            "comment": "This code defines a function that creates a UCT agent for HuggingFace transformer models. It takes in the model and tokenizer, horizon, reward function, UCT arguments, generation args, and whether to plot the tree. The reward function evaluates the reward of a sequence.",
            "location": "\"/media/root/Prima/works/mcts-for-llm/docs/src/dyna_gym/pipelines/uct_for_hf_transformer.py\":0-30",
            "content": "from datetime import datetime\nfrom typing import Callable, Sequence\nimport gym\nimport torch\nimport transformers\nfrom dyna_gym.agents import uct\nfrom dyna_gym.default_policy.hf_default_policy import HuggingFaceDefaultPolicy\nfrom dyna_gym.utils.tree_search_utils import print_tree\ndef uct_for_hf_transformer_pipeline(\n        model: transformers.PreTrainedModel,\n        tokenizer: transformers.PreTrainedTokenizer,\n        horizon: int = 100,\n        reward_func: Callable = None,\n        uct_args: dict = {},\n        model_generation_args: dict = {},\n        should_plot_tree: bool = False,\n        reward_func_input_is_state: bool = False,\n) -> Callable:\n    \"\"\"\n    A wrapped UCT agent for HuggingFace transformer.\n    Args:\n        model_name: The name of a HuggingFace transformer model. If provided, will load the model and tokenizer.\n        model: A HuggingFace transformer model.\n        tokenizer: A HuggingFace tokenizer.\n        horizon: The maximum number of steps to take.\n        reward_func: A function that evaluate the reward of a sequence."
        },
        {
            "comment": "This code initializes a dynamic environment for the UCT agent using the provided parameters. It also adapts the reward function input based on whether it takes tokenized text or token ids as input, and creates the default policy for the gym environment.",
            "location": "\"/media/root/Prima/works/mcts-for-llm/docs/src/dyna_gym/pipelines/uct_for_hf_transformer.py\":31-56",
            "content": "        value_func: A function that evaluate the value of a sequence.\n        uct_args: Arguments for the UCT agent.\n        model_generation_args: Arguments for the model generation.\n        should_plot_tree: Whether to plot the tree after generation.\n        reward_func_input_is_state: Whether the input of the reward function is (token ids, attention masks) or tokenized text.\n    \"\"\"\n    eos_token_id = tokenizer.eos_token_id\n    if not reward_func_input_is_state:\n        # reward function takes tokenized text as input, decode tokeni ids here\n        # if reward function takes token ids as input, this step can be saved\n        def reward_func_(state):\n            ids, attention_mask = state\n            text = tokenizer.decode(ids, skip_special_tokens=True)\n            return reward_func(text)\n    else:\n        reward_func_ = reward_func\n    env = gym.make(\n        'LanguageEnv-v0',\n        terminal_token=eos_token_id,\n        horizon=horizon,\n        reward_func=reward_func_,\n    )\n    default_policy = HuggingFaceDefaultPolicy("
        },
        {
            "comment": "This code initializes a UCT agent for a given environment, horizon, and model. It then defines a \"generate\" function that resets the environment, performs rollouts with the UCT agent's actions, and optionally prints the action tree.",
            "location": "\"/media/root/Prima/works/mcts-for-llm/docs/src/dyna_gym/pipelines/uct_for_hf_transformer.py\":57-88",
            "content": "        env=env,\n        horizon=horizon,\n        model=model,\n        generation_args=model_generation_args,\n    )\n    agent = uct.UCT(\n        default_policy=default_policy,\n        **uct_args\n    )\n    ### Run\n    def generate(input_ids=None, input_str=None, attention_mask=None):\n        assert (input_ids is None) != (input_str is None), \"Only provide one of input_ids and input_str\"\n        if input_str is not None:\n            input_ids = tokenizer.encode(input_str)\n            input_ids = torch.tensor(input_ids).to(model.device)\n        if attention_mask is None:\n            # attend to tokens that are not padding\n            if tokenizer.pad_token_id is None:\n                attention_mask = torch.ones_like(input_ids)\n            else:\n                attention_mask = (input_ids != tokenizer.pad_token_id).long()\n            attention_mask = attention_mask.to(model.device)\n        env.reset(input_ids, attention_mask)\n        # do all rollouts in one step\n        env.step(agent.act(env, done=False))\n        # print tree"
        },
        {
            "comment": "The code plots and saves a tree, then clears the agent for the next generation call. It returns results including output IDs, rewards, and decoded texts.",
            "location": "\"/media/root/Prima/works/mcts-for-llm/docs/src/dyna_gym/pipelines/uct_for_hf_transformer.py\":89-109",
            "content": "        print_tree(agent.root, tokenizer)\n        # optionally, plot the tree and save to a pdf file\n        if should_plot_tree:\n            # plot (and print) the tree\n            from dyna_gym.utils.tree_search_utils import plot_tree\n            filename = f\"tree-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n            plot_tree(agent.root, tokenizer, filename)\n            print(f\"Tree plotted and saved to {filename}.pdf\")\n        results = {\n            'output_ids': agent.rolled_out_trajectories,\n            'rewards': agent.rolled_out_rewards,\n            'texts': [tokenizer.decode(ids, skip_special_tokens=True) for ids in agent.rolled_out_trajectories],\n        }\n        # clear for the next generation call\n        agent.reset()\n        return results\n    return generate"
        }
    ]
}