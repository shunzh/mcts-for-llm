{
    "summary": "This code defines a multithreaded \"benchmark\" function for comparing agent performances in an environment and saves results to CSV, using a pool of agents with specified parameters. It compares UCT and MyRandomAgent on the environment's action space with optional verbose output.",
    "details": [
        {
            "comment": "This code defines a function \"run\" that performs a single episode of an environment, given an agent and environment. It returns the undiscounted return, total time, and discounted return. The agent's act() method is called to choose actions in each time step, and the environment's step() method updates the state based on the chosen action. The code also includes a csv_write function for writing results into CSV files.",
            "location": "\"/media/root/Prima/works/mcts-for-llm/docs/src/dyna_gym/utils/benchmark.py\":0-43",
            "content": "\"\"\"\nGeneric benchmark method:\nRequire:\nagent.reset(param)\nagent.display()\nagent.act(env, done)\nagent.gamma\nenv.reset()\n\"\"\"\nimport gym\nimport csv\nimport numpy as np\nimport statistics as stat\nimport dyna_gym.agents.uct as uct\nimport dyna_gym.agents.my_random_agent as ra\nimport random\nfrom multiprocessing import Pool\ndef csv_write(row, path, mode):\n    with open(path, mode) as csvfile:\n        w = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n        w.writerow(row)\ndef run(agent, env, tmax, verbose=False):\n    \"\"\"\n    Run single episode\n    Return: (undiscounted_return, total_time, discounted_return)\n    \"\"\"\n    done = False\n    undiscounted_return, total_time, discounted_return = 0.0, 0, 0.0\n    if verbose:\n        env.render()\n    for t in range(tmax):\n        action = agent.act(env,done)\n        _, r, done, _ = env.step(action)\n        undiscounted_return += r\n        discounted_return += (agent.gamma**t) * r\n        if verbose:\n            env.render()\n        if (t+1 == tmax) or done:\n            total_time = t+1"
        },
        {
            "comment": "This function benchmarks multiple agents within a single environment using a single thread method. It takes in the environment name, number of environments, agent names, agent objects, parameter lists, parameter names, number of episodes, timeout per episode, whether to save results, saving paths, and verbosity level as input parameters. The function returns undiscounted return, total time, and discounted return.",
            "location": "\"/media/root/Prima/works/mcts-for-llm/docs/src/dyna_gym/utils/benchmark.py\":44-62",
            "content": "            break\n    return undiscounted_return, total_time, discounted_return\ndef singlethread_benchmark(env_name, n_env, agent_name_pool, agent_pool, param_pool, param_names_pool, n_epi, tmax, save, paths_pool, verbose=True):\n    \"\"\"\n    Benchmark multiple agents within a single environment.\n    Single thread method.\n    env_name         : name of the generated environment\n    n_env            : number of generated environment\n    agent_name_pool  : list containing the names of the agents for saving purpose\n    agent_pool       : list containing the agent objects\n    param_pool       : list containing lists of parameters for each agent object\n    param_names_pool : list containing the parameters names\n    n_epi            : number of episodes per generated environment\n    tmax             : timeout for each episode\n    save             : save the results or not\n    paths_pool       : list containing the saving path for each agent\n    verbose          : if true, display informations during benchmark\n    \"\"\""
        },
        {
            "comment": "This code initializes agents for a given number of environments. It checks if the lengths of agent name, agent pool, and parameter pool lists are equal. If saving files, it creates save files for each agent. Then, it iterates over the environments, creates each environment, and resets each agent with its corresponding parameters.",
            "location": "\"/media/root/Prima/works/mcts-for-llm/docs/src/dyna_gym/utils/benchmark.py\":63-83",
            "content": "    assert len(agent_name_pool) == len(agent_pool) == len(param_pool)\n    n_agt = len(param_pool)\n    if save:\n        assert len(paths_pool) == n_agt\n        for _agt in range(n_agt): # Init save files for each agent\n            csv_write(['env_name', 'env_number', 'agent_name', 'agent_number'] + param_names_pool[_agt] + ['epi_number', 'undiscounted_return', 'total_time', 'discounted_return'], paths_pool[_agt], 'w')\n    for _env in range(n_env):\n        env = gym.make(env_name)\n        if verbose:\n            print('Created environment', _env+1, '/', n_env)\n            #env.display()\n        for _agt in range(n_agt):\n            agt_name = agent_name_pool[_agt]\n            agt = agent_pool[_agt]\n            n_prm = len(param_pool[_agt])\n            for _prm in range(n_prm):\n                prm = param_pool[_agt][_prm]\n                agt.reset(prm)\n                if verbose:\n                    print('Created agent', _agt+1, '/', n_agt,'with parameters', _prm+1, '/', n_prm)\n                    agt.display()"
        },
        {
            "comment": "This code iterates over a given number of episodes (n_epi), resetting the environment for each episode. It then runs an agent on the environment using the run function, collecting undiscounted return, total time, and discounted return as results. If saving is enabled, it appends the collected data to a file specified by the paths_pool variable. This code also handles threading by including _thr in the print statement.",
            "location": "\"/media/root/Prima/works/mcts-for-llm/docs/src/dyna_gym/utils/benchmark.py\":84-98",
            "content": "                for _epi in range(n_epi):\n                    if verbose:\n                        print('Environment', env_name, _env+1, '/', n_env, 'agent', agt_name, _prm+1, '/', n_prm,'running episode', _epi+1, '/', n_epi)\n                    env.reset()\n                    undiscounted_return, total_time, discounted_return = run(agt, env, tmax)\n                    if save:\n                        csv_write([env_name, _env, agt_name, _prm] + prm + [_epi, undiscounted_return, total_time, discounted_return], paths_pool[_agt], 'a')\ndef multithread_run(env_name, _env, n_env, env, agt_name, _agt, n_agt, agt, _prm, n_prm, prm, tmax, n_epi, _thr, save, path, verbose, save_period):\n    saving_pool = []\n    for _epi in range(n_epi):\n        if verbose:\n            print('Environment', env_name, _env+1, '/', n_env, 'agent', agt_name, _prm+1, '/', n_prm,'running episode', _epi+1, '/', n_epi, '(thread nb', _thr, ')')\n        env.reset()\n        undiscounted_return, total_time, discounted_return = run(agt, env, tmax)"
        },
        {
            "comment": "This code performs benchmarking of multiple agents in a single environment using multithreading. It takes the environment name, number of environments, agent names for saving purposes, agent objects, parameter lists, and parameter names as inputs. It saves the results periodically if required and writes them to a CSV file specified by the user. The benchmarking is performed in a threaded manner with a configurable save interval and optional verbosity.",
            "location": "\"/media/root/Prima/works/mcts-for-llm/docs/src/dyna_gym/utils/benchmark.py\":99-118",
            "content": "        if save:\n            saving_pool.append([env_name, _env, agt_name, _prm] + prm + [_thr, undiscounted_return, total_time, discounted_return])\n            if len(saving_pool) == save_period:\n                for row in saving_pool:\n                    csv_write(row, path, 'a')\n                saving_pool = []\n    if save:\n        for row in saving_pool:\n            csv_write(row, path, 'a')\ndef multithread_benchmark(env_name, n_env, agent_name_pool, agent_pool, param_pool, param_names_pool, n_epi, tmax, save, paths_pool, n_thread, verbose=True, save_period=1):\n    \"\"\"\n    Benchmark multiple agents within a single environment.\n    Multithread method.\n    env_name         : name of the generated environment\n    n_env            : number of generated environment\n    agent_name_pool  : list containing the names of the agents for saving purpose\n    agent_pool       : list containing the agent objects\n    param_pool       : list containing lists of parameters for each agent object\n    param_names_pool : list containing the parameters names"
        },
        {
            "comment": "This code is initializing a benchmark process for multiple agents in parallel using multi-threading. It asserts the lengths of agent names, agent pools and parameter pools are equal. The number of episodes per thread and total number of threads are determined based on the input. If saving is enabled, it creates save files for each agent. It then creates environments and runs agents in parallel for the specified number of times. If verbose is true, it prints progress information.",
            "location": "\"/media/root/Prima/works/mcts-for-llm/docs/src/dyna_gym/utils/benchmark.py\":119-139",
            "content": "    n_epi            : number of episodes per generated environment\n    tmax             : timeout for each episode\n    save             : save the results or not\n    paths_pool       : list containing the saving path for each agent\n    n_thread         : number of threads\n    verbose          : if true, display informations during benchmark\n    \"\"\"\n    assert len(agent_name_pool) == len(agent_pool) == len(param_pool)\n    pool = Pool(processes=n_thread)\n    n_agt = len(param_pool)\n    n_epi = int(n_epi / n_thread)\n    if save:\n        assert len(paths_pool) == n_agt\n        for _agt in range(n_agt): # Init save files for each agent\n            csv_write(['env_name', 'env_number', 'agent_name', 'param_number'] + param_names_pool[_agt] + ['thread_number', 'undiscounted_return', 'total_time', 'discounted_return'], paths_pool[_agt], 'w')\n    for _env in range(n_env):\n        env = gym.make(env_name)\n        if verbose:\n            print('Created environment', _env+1, '/', n_env)\n            #env.display()\n        for _agt in range(n_agt):"
        },
        {
            "comment": "This code initializes multiple agents with varying parameters, creates threads to run each agent in a given environment, and collects results. The agents are reset with different parameter settings before running multithreaded tests on the provided environment. Results from each thread are collected and returned.",
            "location": "\"/media/root/Prima/works/mcts-for-llm/docs/src/dyna_gym/utils/benchmark.py\":140-167",
            "content": "            agt_name = agent_name_pool[_agt]\n            agt = agent_pool[_agt]\n            n_prm = len(param_pool[_agt])\n            for _prm in range(n_prm):\n                prm = param_pool[_agt][_prm]\n                agt.reset(prm)\n                if verbose:\n                    print('Created agent', _agt+1, '/', n_agt,'with parameters', _prm+1, '/', n_prm)\n                    agt.display()\n                results_pool = []\n                for _thr in range(n_thread):\n                    results_pool.append(pool.apply_async(multithread_run,[env_name, _env, n_env, env, agt_name, _agt, n_agt, agt, _prm, n_prm, prm, tmax, n_epi, _thr+1, save, paths_pool[_agt], verbose, save_period]))\n                for result in results_pool:\n                    result.get()\n#def multinode_benchmark():\n    #TODO\ndef test_multithread():\n    env_name = 'NSFrozenLakeEnv-v0'\n    n_env = 4\n    n_epi = 32\n    tmax = 100\n    n_thread = 4\n    env = gym.make(env_name)\n    agent_name_pool = ['UCT', 'RANDOM']\n    agent_pool = [uct.UCT(env.action_space), ra.MyRandomAgent(env.action_space)]"
        },
        {
            "comment": "The code defines a function `test_singlethread` that tests the benchmarking of single-threaded UCT and random agents on the NSFrozenLakeEnv environment. It sets up the environment, agent names, number of episodes, and maximum time steps per episode. The multithread_benchmark function is then called with various parameters to compare performance.",
            "location": "\"/media/root/Prima/works/mcts-for-llm/docs/src/dyna_gym/utils/benchmark.py\":168-201",
            "content": "    param_names_pool = [\n        ['action_space','rollouts','horizon','gamma','ucb_constant','is_model_dynamic'],\n        ['action_space']\n    ]\n    param_pool = [\n        [[env.action_space,  1, 1, 0.9, 6.36396103068, True],[env.action_space, 10, 10, 0.9, 6.36396103068, True]],\n        [[env.action_space]]\n    ]\n    paths_pool = ['data/test_uct.csv','data/test_random.csv']\n    multithread_benchmark(\n        env_name         = env_name,\n        n_env            = n_env,\n        agent_name_pool  = agent_name_pool,\n        agent_pool       = agent_pool,\n        param_pool       = param_pool,\n        param_names_pool = param_names_pool,\n        n_epi            = n_epi,\n        tmax             = tmax,\n        save             = True,\n        paths_pool       = paths_pool,\n        n_thread         = n_thread,\n        verbose          = True,\n        save_period      = 1\n    )\ndef test_singlethread():\n    env_name = 'NSFrozenLakeEnv-v0'\n    n_env = 2\n    n_epi = 8\n    tmax = 100\n    env = gym.make(env_name)\n    agent_name_pool = ['UCT','RANDOM']"
        },
        {
            "comment": "This code creates a pool of agents and their parameters, then calls `singlethread_benchmark` function to compare agent performances. It uses two agents: UCT (UCT.py) and MyRandomAgent (ra/MyRandomAgent.py), defined on the environment's action space. The parameters for each agent are stored in param_pool, along with their names in param_names_pool. The function saves results into specified paths in paths_pool and executes the comparison with verbose output if True.",
            "location": "\"/media/root/Prima/works/mcts-for-llm/docs/src/dyna_gym/utils/benchmark.py\":202-225",
            "content": "    agent_pool = [uct.UCT(env.action_space), ra.MyRandomAgent(env.action_space)]\n    param_names_pool = [\n        ['action_space','rollouts','horizon','gamma','ucb_constant','is_model_dynamic'],\n        ['action_space']\n    ]\n    param_pool = [\n        [[env.action_space,  10, 100, 0.9, 6.36396103068, True],[env.action_space, 100, 100, 0.9, 6.36396103068, True]],\n        [[env.action_space]]\n    ]\n    paths_pool = ['data/test_uct.csv','data/test_random.csv']\n    singlethread_benchmark(\n        env_name         = env_name,\n        n_env            = n_env,\n        agent_name_pool  = agent_name_pool,\n        agent_pool       = agent_pool,\n        param_pool       = param_pool,\n        param_names_pool = param_names_pool,\n        n_epi            = n_epi,\n        tmax             = tmax,\n        save             = True,\n        paths_pool       = paths_pool,\n        verbose          = True\n    )"
        }
    ]
}